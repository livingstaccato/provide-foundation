[benchmark]
# pytest-benchmark configuration for Foundation performance tests

# Statistical settings for reliable measurements
min_rounds = 5
min_time = 0.000005
max_time = 1.0
calibration_precision = 10

# Disable garbage collection during timing for consistency
disable_gc = false

# Warmup settings (disabled for faster CI)
warmup = false
warmup_iterations = 100000

# Timer selection (use high-resolution timer)
timer = time.perf_counter

# Output settings
columns = min,max,mean,stddev,median,iqr,ops
sort = mean

# Comparison settings  
compare_fail = min:5%  # Fail if performance regresses by >5%
compare_fail_ops = ops:5%

# Histogram settings (for detailed analysis)
histogram = false